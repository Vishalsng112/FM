#@Main Code
#importing Librabries
import tensorflow as tf
import numpy as np
import math
import matplotlib.pyplot as plt
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior() 

#Reading Data
inputs_data 	= np.load('input_state.npy')
setpoints_data  = np.load('setpoints.npy')
controls_data   = np.load('controls.npy')

#Creating State
State = np.concatenate((inputs_data[:,0:3] - setpoints_data[:,0:3], inputs_data[:,3:6], inputs_data[:,6:8], inputs_data[:,9:11]), axis=1)

#Creating Control
Action=controls_data;

#Seperating Training and Test Data. 80% for trining and 20% Test
order = np.argsort(np.random.random(State.shape[0]))
State = State[order]
Action = Action[order]
training_range = int(math.ceil(State.shape[0]*0.8))
train_State = State[0:training_range, :]
train_Action = Action[0:training_range, :]
test_State = State[training_range:,:]
test_Action = Action[training_range:,:]

# Normalizing Data as different components have different units so range will be different 
m= train_State.mean(axis=0)
s = train_State.std(axis=0)
train_State = (train_State - m)/s
test_State = (test_State - m)/s

#Creating Deep Neural Network
output_dim = 4
input_dim = 10
X = tf.placeholder(tf.float32, shape=[None, input_dim])
U = tf.placeholder(tf.float32, shape=[None, output_dim])
with tf.variable_scope('DeepController12218'):
	#creating first layer of 64 neurons as mention in paper and using Relu as activation function
    x = tf.layers.dense(X, 64)
    x = tf.nn.relu(x)
    #creating Second layer of 64 neurons as mention in paper and using Relu as activation function
    x=tf.layers.dense(x,64)
    x = tf.nn.relu(x)
    #creating output layer and tanh as activation function for Output layer
    x = tf.layers.dense(x, output_dim)
    predicted_controls = tf.nn.tanh(x)

#Declaring variables and functions
NUM_EPOCHS = 4500
BATCH_SIZE = 128
#Hubber loss function is used as Loss Function (mentioned in paper).
Loss_function = tf.losses.huber_loss(labels=U, predictions=predicted_controls)
#Adam optimizer as optimazation functon as mentioned in paper with learning rate 1e-3
optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(Loss_function)
#Absoulate difference is used as Error Cost
u_cost = tf.losses.absolute_difference(labels=U, predictions=predicted_controls)

num_batches = int(math.ceil(float(train_State.shape[0])/BATCH_SIZE))
test_num_batches = int(math.ceil(float(test_State.shape[0])/BATCH_SIZE))
print('train_num_batches', num_batches)
print('test_num_batches', test_num_batches)

plot_training_cost = []
plot_test_cost = []
with tf.Session() as sess:
	sess.run(tf.global_variables_initializer())
	saver = tf.train.Saver()
	for epoch in range(NUM_EPOCHS):
	## Training
		running_cost = 0.0
		steps = range(num_batches)
		for step in steps:
				left = step*BATCH_SIZE
				right = min(left + BATCH_SIZE, train_State.shape[0])
				tx = train_State[left:right,:]
				tu = train_Action[left:right,:]
				running_cost +=sess.run([optimizer ,Loss_function, u_cost], feed_dict={X: tx, U:tu})
		training_cost   = running_cost/num_batches
		test_cost = sess.run(u_cost, feed_dict={X:test_State, U: test_Action})
		plot_training_cost.append(training_cost)
		plot_test_cost.append(test_cost)
		print(" Epoch:", '%04d' % (epoch+1), "Training_Cost=", "{:.15f}".format(training_cost) , "Test_Cost=", "{:.15f}".format(test_cost))
	#plt.plot(plot_training_cost)
	plt.plot(plot_test_cost)
	plt.show()
